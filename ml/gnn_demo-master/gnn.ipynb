{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "import gnn.gnn_utils as gnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading train, validation dataset\n",
    "data_path = \"./data\"\n",
    "set_name = \"sub_15_7_200\"\n",
    "############# training set ################\n",
    "inp, arcnode, nodegraph, nodein, labels, _ = gnn_utils.set_load_general(data_path, \"train\", set_name=set_name)\n",
    "inp = [a[:, 1:] for a in inp]\n",
    "############ validation set #############\n",
    "inp_val, arcnode_val, nodegraph_val, nodein_val, labels_val, _ = gnn_utils.set_load_general(data_path, \"validation\", set_name=set_name)\n",
    "inp_val = [a[:, 1:] for a in inp_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(inp[0][0])\n",
    "state_dim = 10\n",
    "output_dim = 2\n",
    "state_threshold = 0.001\n",
    "max_iter = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_w(inp):\n",
    "    with tf.variable_scope('State_net'):\n",
    "        layer1 = tf.layers.dense(inp, 5, activation=tf.nn.sigmoid)\n",
    "        layer2 = tf.layers.dense(layer1, state_dim, activation=tf.nn.sigmoid)\n",
    "        return layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_w(inp):\n",
    "    with tf.variable_scope('Output_net'):\n",
    "        layer1 = tf.layers.dense(inp, 5, activation=tf.nn.sigmoid)\n",
    "        layer2 = tf.layers.dense(layer1, output_dim, activation=None)\n",
    "        return layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init input placeholder\n",
    "tf.reset_default_graph()\n",
    "comp_inp = tf.placeholder(tf.float32, shape=(None, input_dim), name=\"input\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, output_dim), name=\"target\")\n",
    "\n",
    "# state(t) & state(t-1)\n",
    "state = tf.placeholder(tf.float32, shape=(None, state_dim), name=\"state\")\n",
    "state_old = tf.placeholder(tf.float32, shape=(None, state_dim), name=\"old_state\")\n",
    "\n",
    "# arch-node conversion matrix\n",
    "ArcNode = tf.sparse_placeholder(tf.float32, name=\"ArcNode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convergence(a, state, old_state, k):\n",
    "    with tf.variable_scope('Convergence'):\n",
    "        # assign current state to old state\n",
    "        old_state = state\n",
    "        \n",
    "        # 获取子结点上一个时刻的状态\n",
    "        # grub states of neighboring node \n",
    "        gat = tf.gather(old_state, tf.cast(a[:, 0], tf.int32))\n",
    "        \n",
    "        # 去除第一列，即子结点的id\n",
    "        # slice to consider only label of the node and that of it's neighbor \n",
    "        # sl = tf.slice(a, [0, 1], [tf.shape(a)[0], tf.shape(a)[1] - 1])\n",
    "        # equivalent code\n",
    "        sl = a[:, 1:]\n",
    "        \n",
    "        # 将子结点上一个时刻的状态放到最后一列\n",
    "        # concat with retrieved state\n",
    "        inp = tf.concat([sl, gat], axis=1)\n",
    "\n",
    "        # evaluate next state and multiply by the arch-node conversion matrix to obtain per-node states\n",
    "        #计算子结点对父结点状态的贡献\n",
    "        layer1 = f_w(inp)\n",
    "        #聚合子结点对父结点状态的贡献，得到当前时刻的父结点的状态\n",
    "        state = tf.sparse_tensor_dense_matmul(ArcNode, layer1)\n",
    "\n",
    "        # update the iteration counter\n",
    "        k = k + 1\n",
    "    return a, state, old_state, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(a, state, old_state, k):\n",
    "    # evaluate condition on the convergence of the state\n",
    "    with tf.variable_scope('condition'):\n",
    "        # 检查当前状态和上一个时刻的状态的欧式距离是否小于阈值\n",
    "        # evaluate distance by state(t) and state(t-1)\n",
    "        outDistance = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(state, old_state)), 1) + 1e-10)\n",
    "        # vector showing item converged or not (given a certain threshold)\n",
    "        checkDistanceVec = tf.greater(outDistance, state_threshold)\n",
    "        \n",
    "        c1 = tf.reduce_any(checkDistanceVec)\n",
    "        \n",
    "        # 是否达到最大迭代次数\n",
    "        c2 = tf.less(k, max_iter)\n",
    "\n",
    "    return tf.logical_and(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 迭代计算，直到状态达到稳定状态\n",
    "# compute state\n",
    "with tf.variable_scope('Loop'):\n",
    "    k = tf.constant(0)\n",
    "    res, st, old_st, num = tf.while_loop(condition, convergence,\n",
    "                                         [comp_inp, state, state_old, k])\n",
    "    # 计算结点的output\n",
    "    out = g_w(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=out))\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out, 1), tf.argmax(y, 1)), dtype=tf.float32))\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "grads = optimizer.compute_gradients(loss)\n",
    "train_op = optimizer.apply_gradients(grads, name='train_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###train model####\n",
    "num_epoch = 5000\n",
    "# 训练集placeholder输入\n",
    "arcnode_train = tf.SparseTensorValue(indices=arcnode[0].indices, values=arcnode[0].values,\n",
    "                                    dense_shape=arcnode[0].dense_shape)\n",
    "fd_train = {comp_inp: inp[0], state: np.zeros((arcnode[0].dense_shape[0], state_dim)),\n",
    "          state_old: np.ones((arcnode[0].dense_shape[0], state_dim)),\n",
    "          ArcNode: arcnode_train, y: labels}\n",
    "#验证集placeholder输入\n",
    "arcnode_valid = tf.SparseTensorValue(indices=arcnode_val[0].indices, values=arcnode_val[0].values,\n",
    "                                dense_shape=arcnode_val[0].dense_shape)\n",
    "fd_valid = {comp_inp: inp_val[0], state: np.zeros((arcnode_val[0].dense_shape[0], state_dim)),\n",
    "      state_old: np.ones((arcnode_val[0].dense_shape[0], state_dim)),\n",
    "      ArcNode: arcnode_valid, y: labels_val}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    for i in range(0, num_epoch):\n",
    "        _, loss_val, accuracy_val = sess.run(\n",
    "                    [train_op, loss, accuracy],\n",
    "                    feed_dict=fd_train)\n",
    "        if i % 100 == 0:\n",
    "\n",
    "            loss_valid_val, accuracy_valid_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict=fd_valid)\n",
    "            print(\"iter %s\\t training loss: %s,\\t training accuracy: %s,\\t validation loss: %s,\\t validation accuracy: %s\" % \n",
    "                  (i, loss_val, accuracy_val, loss_valid_val, accuracy_valid_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook gnn.ipynb to python\n",
      "[NbConvertApp] Writing 5566 bytes to gnn.py\n"
     ]
    }
   ],
   "source": [
    "try:   \n",
    "    !jupyter nbconvert --to python gnn.ipynb\n",
    "    # python即转化为.py，script即转化为.html\n",
    "    # file_name.ipynb即当前module的文件名\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
